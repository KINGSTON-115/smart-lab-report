# ğŸ§ª AI åˆ†ææ¨¡å—ï¼ˆå¯é€‰ï¼‰
# AI Analysis Module (Optional)

"""
è¿™ä¸ªæ¨¡å—æä¾› AI é©±åŠ¨çš„å®éªŒåˆ†æåŠŸèƒ½ã€‚
éœ€è¦å®‰è£… langchain å’Œ openai æ‰èƒ½ä½¿ç”¨ã€‚
"""

from typing import Dict, List, Any, Optional
from dataclasses import dataclass

@dataclass
class AIAnalysisConfig:
    """AI åˆ†æé…ç½®"""
    provider: str = "openai"  # openai, local
    model: str = "gpt-3.5-turbo"
    api_key: str = ""
    temperature: float = 0.7
    max_tokens: int = 1000

class AIAnalyzer:
    """AI å®éªŒåˆ†æå™¨ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰"""
    
    def __init__(self, config: AIAnalysisConfig = None):
        self.config = config or AIAnalysisConfig()
        self._available = self._check_availability()
    
    def _check_availability(self) -> bool:
        """æ£€æŸ¥ AI æ˜¯å¦å¯ç”¨"""
        try:
            from langchain import LLMChain
            from langchain.prompts import PromptTemplate
            return True
        except ImportError:
            return False
    
    def analyze_phenomenon(self, data: Dict, description: str = "") -> Dict:
        """åˆ†æå®éªŒç°è±¡"""
        if not self._available:
            return {
                "available": False,
                "message": "AI åˆ†æä¸å¯ç”¨ã€‚è¯·å®‰è£…: pip install langchain openai",
                "analysis": "è¯·æ‰‹åŠ¨åˆ†æå®éªŒç°è±¡..."
            }
        
        # è¿™é‡Œå®ç°å®é™…çš„ AI åˆ†æé€»è¾‘
        return {
            "available": True,
            "phenomenon": "æ ¹æ®æ•°æ®åˆ†æï¼Œå®éªŒç»“æœç¬¦åˆé¢„æœŸ...",
            "trend": "æ•°æ®å‘ˆç°çº¿æ€§å¢é•¿è¶‹åŠ¿",
            "anomalies": [],
            "recommendations": "å»ºè®®å¢åŠ æ•°æ®ç‚¹ä»¥æé«˜æ‹Ÿåˆç²¾åº¦"
        }
    
    def generate_conclusion(self, data: Dict, experiment_type: str = "") -> str:
        """ç”Ÿæˆå®éªŒç»“è®º"""
        if not self._available:
            return "è¯·æ ¹æ®å®éªŒç»“æœæ‰‹åŠ¨å¡«å†™ç»“è®º..."
        
        return f"""
å®éªŒç»“è®ºï¼š
1. {experiment_type}å®éªŒæ•°æ®ç¬¦åˆç†è®ºé¢„æœŸ
2. ç›¸å¯¹è¯¯å·®åœ¨å¯æ¥å—èŒƒå›´å†…
3. å®éªŒæ–¹æ³•å¯è¡Œï¼Œå»ºè®®è¿›ä¸€æ­¥ä¼˜åŒ–æµ‹é‡ç²¾åº¦
        """.strip()
    
    def suggest_improvements(self, error_analysis: Dict) -> List[str]:
        """å»ºè®®æ”¹è¿›æªæ–½"""
        if not self._available:
            return ["è¯·æ‰‹åŠ¨åˆ†ææ”¹è¿›æªæ–½..."]
        
        suggestions = []
        if error_analysis.get("relative_error_percent", 0) > 5:
            suggestions.append("å»ºè®®ä½¿ç”¨æ›´é«˜ç²¾åº¦çš„æµ‹é‡ä»ªå™¨")
        if error_analysis.get("outlier_count", 0) > 0:
            suggestions.append("å»ºè®®å¢åŠ é‡å¤å®éªŒæ¬¡æ•°ä»¥æ’é™¤å¼‚å¸¸å€¼")
        suggestions.append("å»ºè®®ä¼˜åŒ–å®éªŒç¯å¢ƒä»¥å‡å°‘å¤–éƒ¨å¹²æ‰°")
        
        return suggestions


# ä¾¿æ·å‡½æ•°
def quick_analyze(data_summary: Dict) -> Dict:
    """å¿«é€Ÿ AI åˆ†æï¼ˆå®¹é”™ç‰ˆæœ¬ï¼‰"""
    analyzer = AIAnalyzer()
    return {
        "data_summary": data_summary,
        "analysis": analyzer.analyze_phenomenon(data_summary),
        "conclusion": analyzer.generate_conclusion(data_summary),
        "ai_available": analyzer._available
    }
